{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e1b04a-d66c-4a75-9bca-0faad3af6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random \n",
    "import unicodedata\n",
    "import string \n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "141ee524-b2f6-4dad-b345-6a96bb05cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# General Settings \n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED) \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TEXT_PORTION_SIZE = 200 \n",
    "NUM_ITER = 5_000 \n",
    "LEARNING_RATE = 0.005\n",
    "EMBEDDING_DIM = 100 \n",
    "HIDDEN_DIM = 128 \n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f39717d5-29d1-404d-98fb-f7b2d1823095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chars in text: 1984768\n"
     ]
    }
   ],
   "source": [
    "# Dataset \n",
    "with open(\"data/anna.txt\", \"r\") as f: \n",
    "    textfile = f.read() \n",
    "\n",
    "# Strip extra spaces \n",
    "textfile = re.sub(\" +\", \" \", textfile)\n",
    "\n",
    "TEXT_LENGTH = len(textfile) \n",
    "print(f\"Number of chars in text: {TEXT_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0624b2-e09a-4eed-a733-c2a9bdadb3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984568"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT_LENGTH - TEXT_PORTION_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd55054-30a9-4916-9c5c-5bbe65ffc15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort of tragedy. 'I'm much obliged for the\n",
      "gratification, my humble respects'--that's all the tragedy. And in\n",
      "platonic love there can be no tragedy, because in that love all is clear\n",
      "and pure, because.\n"
     ]
    }
   ],
   "source": [
    "# Divide the text into similar portions \n",
    "\n",
    "def random_portion(textfile): \n",
    "    # choose a rand int btween 0 and tot. number of chars in df - text_portion_size\n",
    "    start_index = random.randint(0, TEXT_LENGTH - TEXT_PORTION_SIZE)\n",
    "    # from start_idx add the text_portion_size + 1 to get the end_indx\n",
    "    end_index = start_index + TEXT_PORTION_SIZE + 1\n",
    "    return textfile[start_index:end_index]\n",
    "\n",
    "print(random_portion(textfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d700c1-b133-400b-9c02-f1132b77cf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "tensor([ 0,  1, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "# Convert Chars to Tensors\n",
    "def char_to_tensor(text) -> torch.tensor: \n",
    "    _list = [string.printable.index(c) for c in text]\n",
    "    tensor = torch.tensor(_list).long()\n",
    "    return tensor\n",
    "\n",
    "print(string.printable)\n",
    "print(char_to_tensor(\"01abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56d4529e-cf89-465b-b5eb-584fe20990ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([94, 36, 21, 14, 33, 14, 34, 94, 36, 21, 14, 33, 10, 23, 13, 27, 24, 31,\n",
      "        18, 29, 12, 17, 73, 96, 27, 14, 10, 13, 34, 94, 15, 24, 27, 94, 17, 18,\n",
      "        28, 94, 28, 25, 14, 14, 12, 17, 73, 94, 28, 29, 24, 24, 13, 94, 12, 24,\n",
      "        22, 25, 27, 14, 28, 28, 18, 23, 16, 94, 17, 18, 28, 94, 12, 27, 24, 28,\n",
      "        28, 14, 13, 94, 15, 18, 23, 16, 14, 27, 28, 73, 94, 32, 10, 18, 29, 18,\n",
      "        23, 16, 94, 29, 24, 96, 28, 14, 14, 94, 18, 15, 94, 29, 17, 14, 94, 12,\n",
      "        27, 10, 12, 20, 94, 32, 24, 30, 21, 13, 94, 23, 24, 29, 94, 12, 24, 22,\n",
      "        14, 94, 10, 16, 10, 18, 23, 75, 94, 50, 23, 14, 94, 19, 24, 18, 23, 29,\n",
      "        94, 12, 27, 10, 12, 20, 14, 13, 75, 96, 96, 36, 21, 27, 14, 10, 13, 34,\n",
      "        73, 94, 15, 27, 24, 22, 94, 29, 17, 14, 94, 28, 24, 30, 23, 13, 94, 24,\n",
      "        15, 94, 21, 18, 16, 17, 29, 94, 28, 29, 14, 25, 28, 94, 24, 23, 94, 29,\n",
      "        17, 14]), tensor([36, 21, 14, 33, 14, 34, 94, 36, 21, 14, 33, 10, 23, 13, 27, 24, 31, 18,\n",
      "        29, 12, 17, 73, 96, 27, 14, 10, 13, 34, 94, 15, 24, 27, 94, 17, 18, 28,\n",
      "        94, 28, 25, 14, 14, 12, 17, 73, 94, 28, 29, 24, 24, 13, 94, 12, 24, 22,\n",
      "        25, 27, 14, 28, 28, 18, 23, 16, 94, 17, 18, 28, 94, 12, 27, 24, 28, 28,\n",
      "        14, 13, 94, 15, 18, 23, 16, 14, 27, 28, 73, 94, 32, 10, 18, 29, 18, 23,\n",
      "        16, 94, 29, 24, 96, 28, 14, 14, 94, 18, 15, 94, 29, 17, 14, 94, 12, 27,\n",
      "        10, 12, 20, 94, 32, 24, 30, 21, 13, 94, 23, 24, 29, 94, 12, 24, 22, 14,\n",
      "        94, 10, 16, 10, 18, 23, 75, 94, 50, 23, 14, 94, 19, 24, 18, 23, 29, 94,\n",
      "        12, 27, 10, 12, 20, 14, 13, 75, 96, 96, 36, 21, 27, 14, 10, 13, 34, 73,\n",
      "        94, 15, 27, 24, 22, 94, 29, 17, 14, 94, 28, 24, 30, 23, 13, 94, 24, 15,\n",
      "        94, 21, 18, 16, 17, 29, 94, 28, 29, 14, 25, 28, 94, 24, 23, 94, 29, 17,\n",
      "        14, 94]))\n"
     ]
    }
   ],
   "source": [
    "def draw_random_sample(textfile): \n",
    "    text_long = char_to_tensor(random_portion(textfile))\n",
    "    inputs = text_long[:-1]\n",
    "    targets = text_long[1:]\n",
    "    return inputs, targets\n",
    "\n",
    "print(draw_random_sample(textfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0822ec12-f729-49bd-bbae-c1cfd9f9123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "\n",
    "class RNN(torch.nn.Module): \n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        embed_size: int, \n",
    "        hidden_size: int, \n",
    "        output_size: int\n",
    "        ): \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = torch.nn.Embedding(\n",
    "                                    num_embeddings=input_size, \n",
    "                                    embedding_dim=embed_size) \n",
    "        self.rnn = torch.nn.LSTMCell(input_size=embed_size, \n",
    "                                     hidden_size=hidden_size) \n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size) \n",
    "        \n",
    "    def forward(self, character, hidden_state, cell_state):\n",
    "        # expects character as size (batch_size, 1) \n",
    "        \n",
    "        # (batch_size, embedding_dim) = (1, embedding_dim=100) \n",
    "        embedded = self.embed(character) # (1 * 100)\n",
    "        (hidden_state, cell_state) = self.rnn(embedded, (hidden_state, cell_state))\n",
    "        output = self.fc(hidden_state)\n",
    "        return output, hidden_state, cell_state\n",
    "                                              \n",
    "    def init_zero_state(self):\n",
    "        # dimension = (1 x 128)\n",
    "        init_hidden = torch.zeros(1, self.hidden_size).to(DEVICE) \n",
    "        init_cell = torch.zeros(1, self.hidden_size).to(DEVICE)\n",
    "        return (init_hidden, init_cell)\n",
    "                                                                                    \n",
    "                                              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "498f1e12-b609-43f0-b8f7-9fc9b4d173c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED) \n",
    "model = RNN(input_size=len(string.printable), # 100\n",
    "            embed_size=EMBEDDING_DIM,         # 100\n",
    "            hidden_size=HIDDEN_DIM,           # 128\n",
    "            output_size=len(string.printable) # 100\n",
    "           ) \n",
    "model = model.to(DEVICE) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a1749a24-d2a9-4df9-9dad-43950013b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "\n",
    "def evaluate(model, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    ## based on https://github.com/spro/practical-pytorch/\n",
    "    ## blob/master/char-rnn-generation/char-rnn-generation.ipynb\n",
    "\n",
    "    (hidden, cell_state) = model.init_zero_state()\n",
    "    prime_input = char_to_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        inp = prime_input[p].unsqueeze(0)\n",
    "        _, hidden, cell_state = model(inp.to(DEVICE), hidden, cell_state)\n",
    "    inp = prime_input[-1].unsqueeze(0)\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "\n",
    "        outputs, hidden, cell_state = model(inp.to(DEVICE), hidden, cell_state)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = outputs.data.view(-1).div(temperature).exp() # e^{logits / T}\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = string.printable[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_to_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d80ef267-530d-49be-98d8-185594019881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.03 min\n",
      "Iteration 0 | Loss 4.62\n",
      "\n",
      "\n",
      "ThA\n",
      "C8(_NWmsdcrx~\n",
      "AGq40uWn\"?LY\"B5Ckl]7C~=\tR\n",
      "n&u8Wor*K\\/=u;+M0|~@]2L\f",
      "q\n",
      "pYn^.06Bv\tK=Uqv:3Wmw`^C!OUMY\n",
      "K7;&e\n",
      "G^_K\n",
      " +Rn%%nzh*`w'f+31:2zMiS!SV/nZu<]3>EoI!eb*M,f`:M]r\u000b",
      "]*jkgUQVg\u000b",
      "O=nJ_CM1q\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(DEVICE), targets\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TEXT_PORTION_SIZE):\n\u001b[0;32m---> 15\u001b[0m     outputs, hidden, cell_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(outputs, targets[c]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m TEXT_PORTION_SIZE\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, character, hidden_state, cell_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, character, hidden_state, cell_state):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# expects character as size (batch_size, 1) \u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# (batch_size, embedding_dim) = (1, embedding_dim=100) \u001b[39;00m\n\u001b[1;32m     24\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(character) \u001b[38;5;66;03m# (1 * 100)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     (hidden_state, cell_state) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(hidden_state)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden_state, cell_state\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1189\u001b[0m, in \u001b[0;36mLSTMCell.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1187\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched \u001b[38;5;28;01melse\u001b[39;00m hx\n\u001b[0;32m-> 1189\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_cell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[1;32m   1196\u001b[0m     ret \u001b[38;5;241m=\u001b[39m (ret[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m), ret[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlwUlEQVR4nO3de1TUdeL/8deAAooMECUITlpriYmatatitbYLlZt5a08XIilOm2vRWeiyS36zXO0CZRctu5irmd3outbpbmpZakK4Fmpq5o1UdBVhpBKNef/+8Odsk4hAAzO8fT7OmVO85/2ZeX8+h5rn+cxnGIcxxggAAMASIYFeAAAAgD8RNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwSrtAL6C1eTwebd++XVFRUXI4HIFeDgAAaARjjPbt26fExESFhDR8bua4i5vt27fL5XIFehkAAKAZysvL1bVr1wbnHHdxExUVJenQwXE6nQFeDQAAaAy32y2Xy+V9HW/IcRc3h9+KcjqdxA0AAG1MYy4p4YJiAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAVgmauCksLJTD4VBeXl6D86ZOnaqePXuqQ4cOcrlcuvnmm7V///7WWSQAAAh67QK9AEkqKSnRjBkz1Ldv3wbnvfjii7r99ts1e/ZsDR48WOvXr9e1114rh8Ohhx9+uJVWCwAAglnAz9zU1NQoMzNTM2fOVGxsbINzly5dqnPOOUdXXXWVunfvrgsvvFAZGRkqLi5updUCAIBgF/C4ycnJ0bBhw5Senn7MuYMHD1Zpaak3ZjZu3Kh3331XF1988VG3qa2tldvt9rkBAAB7BfRtqaKiIq1YsUIlJSWNmn/VVVdp9+7dOvfcc2WM0U8//aRx48bp//7v/466TUFBgSZNmuSvJQMAgCAXsDM35eXlys3N1QsvvKCIiIhGbfPxxx/rvvvu0xNPPKEVK1bojTfe0DvvvKO77777qNuMHz9e1dXV3lt5ebm/dgEAAAQhhzHGBOKJ582bp9GjRys0NNQ7VldXJ4fDoZCQENXW1vrcJ0nnnXeeBg0apClTpnjHnn/+eY0dO1Y1NTUKCTl2q7ndbkVHR6u6ulpOp9N/OwQAAFpMU16/A/a2VFpamsrKynzGsrOzlZycrPz8/CPCRpJ++OGHIwLm8LwANRoAAAgyAYubqKgopaSk+IxFRkYqLi7OO56VlaWkpCQVFBRIkoYPH66HH35Y/fv318CBA7VhwwbdeeedGj58eL0xBAAAjj9B8Xdujmbr1q0+Z2omTJggh8OhCRMmaNu2bTrppJM0fPhw3XvvvQFcJQAACCYBu+YmULjmBgCAtqcpr98B/zs3AAAA/kTcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqwRN3BQWFsrhcCgvL++oc84//3w5HI4jbsOGDWu9hQIAgKDWLtALkKSSkhLNmDFDffv2bXDeG2+8oQMHDnh/3rNnj/r166fLLruspZcIAADaiICfuampqVFmZqZmzpyp2NjYBueecMIJSkhI8N7mz5+vjh07EjcAAMAr4HGTk5OjYcOGKT09vcnbzpo1S1deeaUiIyOPOqe2tlZut9vnBgAA7BXQt6WKioq0YsUKlZSUNHnb4uJirVq1SrNmzWpwXkFBgSZNmtTcJQIAgDYmYGduysvLlZubqxdeeEERERFN3n7WrFnq06ePBgwY0OC88ePHq7q62nsrLy9v7pIBAEAbELAzN6Wlpdq1a5fOOuss71hdXZ0WL16s6dOnq7a2VqGhofVu+/3336uoqEiTJ08+5vOEh4crPDzcb+sGAADBLWBxk5aWprKyMp+x7OxsJScnKz8//6hhI0mvvvqqamtrdfXVV7f0MgEAQBsTsLiJiopSSkqKz1hkZKTi4uK841lZWUpKSlJBQYHPvFmzZmnUqFGKi4trtfUCAIC2ISj+zs3RbN26VSEhvpcFrVu3Tp999pk+/PDDAK0KAAAEM4cxxgR6Ea3J7XYrOjpa1dXVcjqdgV4OAABohKa8fgf879wAAAD4E3EDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqzYqb8vJyfffdd96fi4uLlZeXp6efftpvCwMAAGiOZsXNVVddpUWLFkmSKioqdMEFF6i4uFh33HGHJk+e7NcFAgAANEWz4mbVqlUaMGCAJOmVV15RSkqKli5dqhdeeEFz5szx5/oAAACapFlxc/DgQYWHh0uSPvroI40YMUKSlJycrB07dvhvdQAAAE3UrLjp3bu3nnrqKX366aeaP3++hg4dKknavn274uLi/LpAAACApmhW3Nx///2aMWOGzj//fGVkZKhfv36SpLfeesv7dhUAAEAgOIwxpjkb1tXVye12KzY21ju2efNmdezYUZ07d/bbAv3N7XYrOjpa1dXVcjqdgV4OAABohKa8fjfrzM2PP/6o2tpab9hs2bJFU6dO1bp164I6bAAAgP2aFTcjR47U3LlzJUlVVVUaOHCgHnroIY0aNUpPPvmkXxcIAADQFM2KmxUrVui8886TJL322muKj4/Xli1bNHfuXD366KN+XSAAAEBTNCtufvjhB0VFRUmSPvzwQ1166aUKCQnRoEGDtGXLFr8uEAAAoCmaFTc9evTQvHnzVF5erg8++EAXXnihJGnXrl1cpAsAAAKqWXFz11136bbbblP37t01YMAApaamSjp0Fqd///5+XSAAAEBTNPuj4BUVFdqxY4f69eunkJBDjVRcXCyn06nk5GS/LtKf+Cg4AABtT1Nev9s190kSEhKUkJDg/Xbwrl278gf8AABAwDXrbSmPx6PJkycrOjpa3bp1U7du3RQTE6O7775bHo/H32sEAABotGadubnjjjs0a9YsFRYW6pxzzpEkffbZZ/rnP/+p/fv369577/XrIgEAABqrWdfcJCYm6qmnnvJ+G/hhb775pm688UZt27bNbwv0N665AQCg7Wnxr1+orKys96Lh5ORkVVZWNuchAQAA/KJZcdOvXz9Nnz79iPHp06erb9++v3pRAAAAzdWsa24eeOABDRs2TB999JH3b9wsW7ZM5eXlevfdd/26QAAAgKZo1pmbIUOGaP369Ro9erSqqqpUVVWlSy+9VKtXr9Zzzz3n7zUCAAA0WrPiRjp0UfG9996r119/Xa+//rruuece7d27V7NmzWrW4xUWFsrhcCgvL6/BeVVVVcrJyVGXLl0UHh6u008/nbNFAADAq9l/xM+fSkpKNGPGjGNer3PgwAFdcMEF6ty5s1577TUlJSVpy5YtiomJaZ2FAgCAoBfwuKmpqVFmZqZmzpype+65p8G5s2fPVmVlpZYuXar27dtLkrp3794KqwQAAG1Fs9+W8pecnBwNGzZM6enpx5z71ltvKTU1VTk5OYqPj1dKSoruu+8+1dXVHXWb2tpaud1unxsAALBXk87cXHrppQ3eX1VV1aQnLyoq0ooVK1RSUtKo+Rs3btTChQuVmZmpd999Vxs2bNCNN96ogwcPauLEifVuU1BQoEmTJjVpXQAAoO1qUtxER0cf8/6srKxGPVZ5eblyc3M1f/58RURENGobj8ejzp076+mnn1ZoaKjOPvtsbdu2TVOmTDlq3IwfP1633HKL92e32y2Xy9Wo5wMAAG1Pk+LmmWee8dsTl5aWateuXTrrrLO8Y3V1dVq8eLGmT5+u2tpahYaG+mzTpUsXtW/f3me8V69eqqio0IEDBxQWFnbE84SHhys8PNxv6wYAAMEtYBcUp6WlqayszGcsOztbycnJys/PPyJsJOmcc87Riy++KI/Ho5CQQ5cLrV+/Xl26dKk3bAAAwPEnYBcUR0VFKSUlxecWGRmpuLg4paSkSJKysrI0fvx47zY33HCDKisrlZubq/Xr1+udd97Rfffdp5ycnEDtBgAACDIB/yh4Q7Zu3eo9QyNJLpdLH3zwgW6++Wb17dtXSUlJys3NVX5+fgBXCQAAgonDGGMCvYjW1JSvTAcAAMGhKa/fAf87NwAAAP5E3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsETdwUFhbK4XAoLy/vqHPmzJkjh8Phc4uIiGi9RQIAgKDXLtALkKSSkhLNmDFDffv2PeZcp9OpdevWeX92OBwtuTQAANDGBPzMTU1NjTIzMzVz5kzFxsYec77D4VBCQoL3Fh8f3+D82tpaud1unxsAALBXwOMmJydHw4YNU3p6eqPm19TUqFu3bnK5XBo5cqRWr17d4PyCggJFR0d7by6Xyx/LBgAAQSqgcVNUVKQVK1aooKCgUfN79uyp2bNn680339Tzzz8vj8ejwYMH67vvvjvqNuPHj1d1dbX3Vl5e7q/lAwCAIBSwa27Ky8uVm5ur+fPnN/qi4NTUVKWmpnp/Hjx4sHr16qUZM2bo7rvvrneb8PBwhYeH+2XNAAAg+AUsbkpLS7Vr1y6dddZZ3rG6ujotXrxY06dPV21trUJDQxt8jPbt26t///7asGFDSy8XAAC0EQGLm7S0NJWVlfmMZWdnKzk5Wfn5+ccMG+lQDJWVleniiy9uqWUCAIA2JmBxExUVpZSUFJ+xyMhIxcXFecezsrKUlJTkvSZn8uTJGjRokHr06KGqqipNmTJFW7Zs0V/+8pdWXz8AAAhOQfF3bo5m69atCgn53zXPe/fu1fXXX6+KigrFxsbq7LPP1tKlS3XGGWcEcJUAACCYOIwxJtCLaE1ut1vR0dGqrq6W0+kM9HIAAEAjNOX1O+B/5wYAAMCfiBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABYhbgBAABWIW4AAIBVgiZuCgsL5XA4lJeX16j5RUVFcjgcGjVqVIuuCwAAtC1BETclJSWaMWOG+vbt26j5mzdv1m233abzzjuvhVcGAADamoDHTU1NjTIzMzVz5kzFxsYec35dXZ0yMzM1adIknXrqqa2wQgAA0JYEPG5ycnI0bNgwpaenN2r+5MmT1blzZ1133XWNml9bWyu32+1zAwAA9moXyCcvKirSihUrVFJS0qj5n332mWbNmqWVK1c2+jkKCgo0adKkZq4QAAC0NQE7c1NeXq7c3Fy98MILioiIOOb8ffv2acyYMZo5c6ZOPPHERj/P+PHjVV1d7b2Vl5f/mmUDAIAg5zDGmEA88bx58zR69GiFhoZ6x+rq6uRwOBQSEqLa2lqf+1auXKn+/fv7jHk8HklSSEiI1q1bp9/85jfHfF63263o6GhVV1fL6XT6cY8AAEBLacrrd8DelkpLS1NZWZnPWHZ2tpKTk5Wfn+8TMZKUnJx8xPwJEyZo3759mjZtmlwuV4uvGQAABL+AxU1UVJRSUlJ8xiIjIxUXF+cdz8rKUlJSkgoKChQREXHE/JiYGEk6YhwAABy/AnpB8bFs3bpVISEB/0AXAABoQwJ2zU2gcM0NAABtT1NevzktAgAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMAAKxC3AAAAKsQNwAAwCrEDQAAsApxAwAArELcAAAAqxA3AADAKsQNAACwCnEDAACs0i7QC2htxhhJktvtDvBKAABAYx1+3T78Ot6Q4y5u9u3bJ0lyuVwBXgkAAGiqffv2KTo6usE5DtOYBLKIx+PR9u3bFRUVJYfDEejlBJzb7ZbL5VJ5ebmcTmegl2MtjnPr4Di3Do5z6+FY/48xRvv27VNiYqJCQhq+qua4O3MTEhKirl27BnoZQcfpdB73/+G0Bo5z6+A4tw6Oc+vhWB9yrDM2h3FBMQAAsApxAwAArELcHOfCw8M1ceJEhYeHB3opVuM4tw6Oc+vgOLcejnXzHHcXFAMAALtx5gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXixnKVlZXKzMyU0+lUTEyMrrvuOtXU1DS4zf79+5WTk6O4uDh16tRJf/7zn7Vz58565+7Zs0ddu3aVw+FQVVVVC+xB29ASx/nLL79URkaGXC6XOnTooF69emnatGktvStB5/HHH1f37t0VERGhgQMHqri4uMH5r776qpKTkxUREaE+ffro3Xff9bnfGKO77rpLXbp0UYcOHZSenq5vvvmmJXehTfDncT548KDy8/PVp08fRUZGKjExUVlZWdq+fXtL70bQ8/fv88+NGzdODodDU6dO9fOq2yADqw0dOtT069fPfP755+bTTz81PXr0MBkZGQ1uM27cOONyucyCBQvMF198YQYNGmQGDx5c79yRI0eaP/3pT0aS2bt3bwvsQdvQEsd51qxZ5m9/+5v5+OOPzbfffmuee+4506FDB/PYY4+19O4EjaKiIhMWFmZmz55tVq9eba6//noTExNjdu7cWe/8JUuWmNDQUPPAAw+YNWvWmAkTJpj27dubsrIy75zCwkITHR1t5s2bZ7788kszYsQIc8opp5gff/yxtXYr6Pj7OFdVVZn09HTz8ssvm7Vr15ply5aZAQMGmLPPPrs1dyvotMTv82FvvPGG6devn0lMTDSPPPJIC+9J8CNuLLZmzRojyZSUlHjH3nvvPeNwOMy2bdvq3aaqqsq0b9/evPrqq96xr7/+2kgyy5Yt85n7xBNPmCFDhpgFCxYc13HT0sf552688Ubzhz/8wX+LD3IDBgwwOTk53p/r6upMYmKiKSgoqHf+5ZdfboYNG+YzNnDgQPPXv/7VGGOMx+MxCQkJZsqUKd77q6qqTHh4uHnppZdaYA/aBn8f5/oUFxcbSWbLli3+WXQb1FLH+bvvvjNJSUlm1apVplu3bsSNMYa3pSy2bNkyxcTE6Le//a13LD09XSEhIVq+fHm925SWlurgwYNKT0/3jiUnJ+vkk0/WsmXLvGNr1qzR5MmTNXfu3GN+gZntWvI4/1J1dbVOOOEE/y0+iB04cEClpaU+xygkJETp6elHPUbLli3zmS9JF110kXf+pk2bVFFR4TMnOjpaAwcObPC426wljnN9qqur5XA4FBMT45d1tzUtdZw9Ho/GjBmjv//97+rdu3fLLL4NOr5flSxXUVGhzp07+4y1a9dOJ5xwgioqKo66TVhY2BH/A4qPj/duU1tbq4yMDE2ZMkUnn3xyi6y9LWmp4/xLS5cu1csvv6yxY8f6Zd3Bbvfu3aqrq1N8fLzPeEPHqKKiosH5h//ZlMe0XUsc51/av3+/8vPzlZGRcdx++WNLHef7779f7dq109/+9jf/L7oNI27aoNtvv10Oh6PB29q1a1vs+cePH69evXrp6quvbrHnCAaBPs4/t2rVKo0cOVITJ07UhRde2CrPCfjDwYMHdfnll8sYoyeffDLQy7FKaWmppk2bpjlz5sjhcAR6OUGlXaAXgKa79dZbde211zY459RTT1VCQoJ27drlM/7TTz+psrJSCQkJ9W6XkJCgAwcOqKqqyuesws6dO73bLFy4UGVlZXrttdckHfr0iSSdeOKJuuOOOzRp0qRm7llwCfRxPmzNmjVKS0vT2LFjNWHChGbtS1t04oknKjQ09IhP6tV3jA5LSEhocP7hf+7cuVNdunTxmXPmmWf6cfVtR0sc58MOh82WLVu0cOHC4/asjdQyx/nTTz/Vrl27fM6g19XV6dZbb9XUqVO1efNm/+5EWxLoi37Qcg5f6PrFF194xz744INGXej62muvecfWrl3rc6Hrhg0bTFlZmfc2e/ZsI8ksXbr0qFf926yljrMxxqxatcp07tzZ/P3vf2+5HQhiAwYMMDfddJP357q6OpOUlNTgBZiXXHKJz1hqauoRFxQ/+OCD3vurq6u5oNjPx9kYYw4cOGBGjRplevfubXbt2tUyC29j/H2cd+/e7fP/4rKyMpOYmGjy8/PN2rVrW25H2gDixnJDhw41/fv3N8uXLzefffaZOe2003w+ovzdd9+Znj17muXLl3vHxo0bZ04++WSzcOFC88UXX5jU1FSTmpp61OdYtGjRcf1pKWNa5jiXlZWZk046yVx99dVmx44d3tvx9EJRVFRkwsPDzZw5c8yaNWvM2LFjTUxMjKmoqDDGGDNmzBhz++23e+cvWbLEtGvXzjz44IPm66+/NhMnTqz3o+AxMTHmzTffNF999ZUZOXIkHwX383E+cOCAGTFihOnatatZuXKlz+9vbW1tQPYxGLTE7/Mv8WmpQ4gby+3Zs8dkZGSYTp06GafTabKzs82+ffu892/atMlIMosWLfKO/fjjj+bGG280sbGxpmPHjmb06NFmx44dR30O4qZljvPEiRONpCNu3bp1a8U9C7zHHnvMnHzyySYsLMwMGDDAfP755977hgwZYq655hqf+a+88oo5/fTTTVhYmOndu7d55513fO73eDzmzjvvNPHx8SY8PNykpaWZdevWtcauBDV/HufDv+/13X7+38DxyN+/z79E3BziMOb/XzABAABgAT4tBQAArELcAAAAqxA3AADAKsQNAACwCnEDAACsQtwAAACrEDcAAMAqxA0AALAKcQMgqHTv3l1Tp04N9DIAtGHEDXCcuvbaazVq1Cjvz+eff77y8vJa7fnnzJnj843oh5WUlGjs2LGtto7GWrx4sYYPH67ExEQ5HA7NmzfviDnGGN11113q0qWLOnTooPT0dH3zzTc+cyorK5WZmSmn06mYmBhdd911qqmp8Znz1Vdf6bzzzlNERIRcLpceeOCBltw1wDrEDQC/OnDgwK/a/qSTTlLHjh39tBr/+f7779WvXz89/vjjR53zwAMP6NFHH9VTTz2l5cuXKzIyUhdddJH279/vnZOZmanVq1dr/vz5evvtt7V48WKfmHO73brwwgvVrVs3lZaWasqUKfrnP/+pp59+ukX3D7BKgL/bCkCAXHPNNWbkyJHef9cvvuBw06ZNxphD304+dOhQExkZaTp37myuvvpq89///tf7OEOGDDE5OTkmNzfXxMXFmfPPP98YY8xDDz1kUlJSTMeOHU3Xrl3NDTfc4P0y0cNftvrz28SJE40xR37x35YtW8yIESNMZGSkiYqKMpdddpn3W5SNOfQFo/369TNz58413bp1M06n01xxxRXG7XYfdd+zs7NNnz59zP79+40xxtTW1pozzzzTjBkzplHHTpL597//7TPm8XhMQkKCmTJlinesqqrKhIeHm5deeskYY8yaNWuMJFNSUuKd89577xmHw2G2bdtmjDHmiSeeMLGxsT7fnp2fn2969uzZqLUBMIYzNwA0bdo0paam6vrrr9eOHTu0Y8cOuVwuVVVV6Y9//KP69++vL774Qu+//7527typyy+/3Gf7Z599VmFhYVqyZImeeuopSVJISIgeffRRrV69Ws8++6wWLlyof/zjH5KkwYMHa+rUqXI6nd7nu+22245Yl8fj0ciRI1VZWalPPvlE8+fP18aNG3XFFVf4zPv22281b948vf3223r77bf1ySefqLCw8Kj7++ijj+r777/X7bffLkm64447VFVVpenTpzf7GG7atEkVFRVKT0/3jkVHR2vgwIFatmyZJGnZsmWKiYnRb3/7W++c9PR0hYSEaPny5d45v//97xUWFuadc9FFF2ndunXau3dvs9cHHE/aBXoBAAIvOjpaYWFh6tixoxISErzj06dPV//+/XXfffd5x2bPni2Xy6X169fr9NNPlySddtppR1wX8vPrd7p376577rlH48aN0xNPPKGwsDBFR0fL4XD4PN8vLViwQGVlZdq0aZNcLpckae7cuerdu7dKSkr0u9/9TtKhCJozZ46ioqIkSWPGjNGCBQt077331vu4nTp10vPPP68hQ4YoKipKU6dO1aJFi+R0Optw1HxVVFRIkuLj433G4+PjvfdVVFSoc+fOPve3a9dOJ5xwgs+cU0455YjHOHxfbGxss9cIHC84cwPgqL788kstWrRInTp18t6Sk5MlHTpbctjZZ599xLYfffSR0tLSlJSUpKioKI0ZM0Z79uzRDz/80Ojn//rrr+VyubxhI0lnnHGGYmJi9PXXX3vHunfv7g0bSerSpYt27drV4GOnpqbqtttu0913361bb71V5557bqPXBSC4ETcAjqqmpkbDhw/XypUrfW7ffPONfv/733vnRUZG+my3efNmXXLJJerbt69ef/11lZaWei/E/bUXHNenffv2Pj87HA55PJ4Gt/F4PFqyZIlCQ0O1YcOGX72Gw2egdu7c6TO+c+dO730JCQlHRNdPP/2kyspKnzn1PcbPnwNAw4gbAJKksLAw1dXV+YydddZZWr16tbp3764ePXr43H4ZND9XWloqj8ejhx56SIMGDdLpp5+u7du3H/P5fqlXr14qLy9XeXm5d2zNmjWqqqrSGWec0Yy9/J8pU6Zo7dq1+uSTT/T+++/rmWee+VWPd8oppyghIUELFizwjrndbi1fvlypqamSDp0tqqqqUmlpqXfOwoUL5fF4NHDgQO+cxYsX6+DBg9458+fPV8+ePXlLCmgk4gaApENv7SxfvlybN2/W7t275fF4lJOTo8rKSmVkZKikpETffvutPvjgA2VnZzcYJj169NDBgwf12GOPaePGjXruuee8Fxr//Plqamq0YMEC7d69u963q9LT09WnTx9lZmZqxYoVKi4uVlZWloYMGeJzUW5T/ec//9Fdd92lf/3rXzrnnHP08MMPKzc3Vxs3bjzqNjU1Nd4zV9KhC4hXrlyprVu3Sjp0tigvL0/33HOP3nrrLZWVlSkrK0uJiYnevyfUq1cvDR06VNdff72Ki4u1ZMkS3XTTTbryyiuVmJgoSbrqqqsUFham6667TqtXr9bLL7+sadOm6ZZbbmn2/gLHnUB/XAtAYPz8o+DGGLNu3TozaNAg06FDB5+Pgq9fv96MHj3axMTEmA4dOpjk5GSTl5dnPB6PMebQR8Fzc3OPePyHH37YdOnSxXTo0MFcdNFFZu7cuUaS2bt3r3fOuHHjTFxcnF8+Cv5zjzzyiOnWrVu9+/3jjz+aM844w4wdO9ZnfMSIEWbw4MHmp59+qne7+j6+Lslcc8013jkej8fceeedJj4+3oSHh5u0tDSzbt06n8fZs2ePycjIMJ06dTJOp9NkZ2d7PyJ/2JdffmnOPfdcEx4ebpKSkkxhYWG9awJQP4cxxgQurQAAAPyLt6UAAIBViBsAAGAV4gYAAFiFuAEAAFYhbgAAgFWIGwAAYBXiBgAAWIW4AQAAViFuAACAVYgbAABgFeIGAABY5f8BmgEBU8pJ2vsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for iteration in range(NUM_ITER):\n",
    "\n",
    "    hidden, cell_state = model.init_zero_state()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0.\n",
    "    inputs, targets = draw_random_sample(textfile)\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "    \n",
    "    for c in range(TEXT_PORTION_SIZE):\n",
    "        outputs, hidden, cell_state = model(inputs[c].unsqueeze(0), hidden, cell_state)\n",
    "        loss += torch.nn.functional.cross_entropy(outputs, targets[c].view(1))\n",
    "\n",
    "    loss /= TEXT_PORTION_SIZE\n",
    "    loss.backward()\n",
    "    \n",
    "    ### UPDATE MODEL PARAMETERS\n",
    "    optimizer.step()\n",
    "\n",
    "    ### LOGGING\n",
    "    with torch.no_grad():\n",
    "        if iteration % 200 == 0:\n",
    "            print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "            print(f'Iteration {iteration} | Loss {loss.item():.2f}\\n\\n')\n",
    "            print(evaluate(model, 'Th', 200), '\\n')\n",
    "            print(50*'=')\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "            plt.clf()\n",
    "            plt.plot(range(len(loss_list)), loss_list)\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Iteration x 1000')\n",
    "            plt.savefig('loss1.pdf')\n",
    "            \n",
    "plt.clf()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration x 1000')\n",
    "plt.plot(range(len(loss_list)), loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe7330-98cf-46fd-8b94-5ee5f17e3c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
